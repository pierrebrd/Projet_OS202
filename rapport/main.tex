\documentclass[a4paper, 12pt]{report}

\usepackage{titlepic}
\usepackage{booktabs}
\usepackage{longtable}
\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.18}

\title{Projet d'OS202: Feux de forêts}
\author{Pierre \textsc{Bordeau}, Gabriel \textsc{Dupuis}}
\date{\today}
% \titlepic{\includegraphics[width=.2\textwidth]{img/logo}}

\usepackage[left=2cm, right=2cm, top=2.5cm, bottom=3cm]{geometry}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc} % Pour reconnaitre les caractères accentués
\usepackage[french]{babel}

\usepackage{graphicx}
\usepackage{float}
\usepackage{appendix}

\usepackage{minted}
\setminted{frame=single, linenos, mathescape=true, breaklines}

% Define a custom fancy page style
\usepackage{fancyhdr}
\fancypagestyle{mystyle}{
    \fancyhf{}
    % \fancyhead[L]{\includegraphics[height=1cm]{img/logo}}
    \fancyhead[R]{\thepage}
    \renewcommand{\headrulewidth}{0.4pt}
    \setlength{\headheight}{33pt}
}

% Set the default page style to be the custom one
\pagestyle{mystyle}
\thispagestyle{mystyle}

\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[thinc]{esdiff}

\usepackage{tgpagella}
\renewcommand{\ttdefault}{lmtt} %nécessaire avec bookman et kerkis, et un peu avec tgpagella
\usepackage[fontsize=12pt]{fontsize}

\usepackage{setspace}
\renewcommand{\baselinestretch}{1.2} 

\usepackage[hidelinks]{hyperref}

\renewcommand{\thesection}{\arabic{section}}
\renewcommand{\thesubsection}{\thesection.\arabic{subsection}}


\begin{document}

\maketitle
\newpage
\tableofcontents
\newpage

\setlength{\parskip}{0.5\baselineskip plus 0.3\baselineskip minus 0.2\baselineskip} % Permet d'ajouter automatiquement un espace entre les paragraphes. Pour juste aller à la ligne sans sauter de ligne, écrirer \\ puis écrire ce qui sera sur la nouvelle ligne 
\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}{0pt}{-1em}{\normalfont\normalsize\bfseries}}
\makeatother

\section{Première étape}
\subsection{Question 1}

Voici un exemple de ce que \texttt{lscpu} donne :


\begin{minted}[linenos, frame=lines]{bash}
    Architecture :                              x86_64
      Mode(s) opératoire(s) des processeurs :   32-bit, 64-bit
      Address sizes:                            48 bits physical, 48 bits virtual
      Boutisme :                                Little Endian
    Processeur(s) :                             16
      Liste de processeur(s) en ligne :         0-15
    Identifiant constructeur :                  AuthenticAMD
      Nom de modèle :                           AMD Ryzen 7 7735U with Radeon Graphics
        Famille de processeur :                 25
        Modèle :                                68
        Thread(s) par cœur :                    2
        Cœur(s) par socket :                    8
        Socket(s) :                             1
        Révision :                              1
        Vitesse maximale du processeur en MHz : 4819,0000
        Vitesse minimale du processeur en MHz : 400,0000
        BogoMIPS :                              5390.15
    Virtualization features:                    
      Virtualisation :                          AMD-V
    Caches (sum of all):                        
      L1d:                                      256 KiB (8 instances)
      L1i:                                      256 KiB (8 instances)
      L2:                                       4 MiB (8 instances)
      L3:                                       16 MiB (1 instance)
    NUMA:                                       
      Nœud(s) NUMA :                            1
      Nœud NUMA 0 de processeur(s) :            0-15
    Vulnerabilities:                            
      Gather data sampling:                     Not affected
      Itlb multihit:                            Not affected
      L1tf:                                     Not affected
      Mds:                                      Not affected
      Meltdown:                                 Not affected
      Mmio stale data:                          Not affected
      Reg file data sampling:                   Not affected
      Retbleed:                                 Not affected
      Spec rstack overflow:                     Vulnerable: Safe RET, no microcode
      Spec store bypass:                        Mitigation; Speculative Store Bypass disabled via prctl
      Spectre v1:                               Mitigation; usercopy/swapgs barriers and __user pointer sanitization
      Spectre v2:                               Mitigation; Retpolines; IBPB conditional; IBRS_FW; STIBP always-on; RSB filling; PBRSB-eIBRS
                                                 Not affected; BHI Not affected
      Srbds:                                    Not affected
      Tsx async abort:                          Not affected
\end{minted}

On en extrait sur les différentes machines qui seront utilisées pour les calculs:
\begin{table}[h]
  \centering
  \begin{tabular}{|c|c|c|c|}
    \hline
    Machine          & Gabriel & Pierre & ENSTA - serveur info1 \\ \hline
    Coeurs           & 8       & 2      & 80                    \\ \hline
    Mémoire cache L1 & 512 KiB & 64 KiB & 2,6 MiB               \\ \hline
    Mémoire cache L2 & 4 MiB   & 1 MiB  & 40 MiB                \\ \hline
    Mémoire cache L3 & 16 MiB  & 4 MiB  & 55 MiB x 2 instances  \\ \hline
  \end{tabular}
  \caption{Table}
  \label{tab:3x3_table}
\end{table}

Après avoir créé une fonction mesurant le temps d'exécution d'une méthode donnée, on obtient:
\begin{table}[h]
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
    Moyenne temporelle du pas de temps   & 8       & 2      \\ \hline
    Moyenne temporelle de l'affichage L1 & 512 KiB & 64 KiB \\ \hline
  \end{tabular}
  \caption{Table}
  \label{tab:3x3_table}
\end{table}
\subsection{Question 2}

On écrit une fonction permettant de mesurer le temps d'éxecution d'une méthode associée à un objet donné:
\begin{minted}[breakanywhere]{c++}
// Fonction générique pour mesurer le temps d'exécution d'une méthode
template<typename Obj, typename Method, typename... Args>
auto measure_time(bool condition, Obj&& objet, Method&& methode, Args&&... args) {
    if(condition){
        auto start = std::chrono::high_resolution_clock::now();
    
        auto result = (std::forward<Obj>(objet).*std::forward<Method>(methode))(std::forward<Args>(args)...);
    
        auto stop = std::chrono::high_resolution_clock::now();
        auto duration = std::chrono::duration_cast<std::chrono::microseconds>(stop - start);
    
        std::cout << "Temps d'exécution : " << duration.count() << " microsecondes" << std::endl;
        return result;
    }
    else{
        auto result = (std::forward<Obj>(objet).*std::forward<Method>(methode))(std::forward<Args>(args)...);
        return result;
    }
}
\end{minted}
% Et on change l'appel de \mintinline{c++}{simu.update()) par \mintinline{c++}{measure_time(((simu.time_step() & 31) == 0), simu, &Model::update)}.

On obtient alors le tableau de moyennes:
\begin{table}[H]
  \centering
  \begin{tabular}{|c|c|c|c|}
    \hline
    n   & Moyenne temps d'exécution pas de temps durant la simulation ($\mu s$) & Moyenne temps d'exécution pas de temps en régime permanent ($\mu s$) & Moyenne temps d'affichage ($\mu s$) \\
    \hline
    20  & 215                                                                   & 15                                                                   & 762                                 \\
    \hline
    50  & 755                                                                   & 24                                                                   & 827                                 \\
    \hline
    100 & 1590                                                                  & 30                                                                   & 1653                                \\
    \hline
  \end{tabular}
  \caption{Table}
  \label{tab:3x3_table}
\end{table}


\subsection{Question 3}

On parallélise l'avancement en temps (mise à jour de la simulation au fil du temps) avec OpenMP. C'est donc la méthode \mintinline{c++}{Model::update()} qui est parallélisée.

D'abord, en analysant bien le code actuel de la méthode, nous avons remarqué qu'il ne se prête pas très bien à la parallélisation. En effet, on boucle sur chaque cellule du feu actuel (\mintinline{c++}{m_fire_front}), et on met à jour la cellule actuelle ainsi que ses voisines si besoin. Le problème est donc que lorsque qu'on arrive sur une cellule, elle peut avoir déjà été modifiée lorsqu'on étudiait une de ses voisines. C'est notamment le cas pour la carte de l'incendie, \mintinline{c++}{m_fire_map}.

On aura donc du mal à reproduire exactement la même simulation avec un code parallélisé, car on ne peut pas garantir que les cellules sont mises à jour dans le même ordre, ce n'est pas possible avec plusieurs threads.

La parallélisation a été faite en créant d'abord des vecteurs dans lesquels les threads pourront stocker les cellules à mettre à jour et à supprimer. Ensuite, une fois que tous les calculs sont effectués en parallèle, un unique thread met à jour les cartes globales.

La version initiale du code utilise une boucle sur les éléments de la \mintinline{c++}{std::unordered_map} pour traiter les cellules. Le problème est que comme c'est une structure de données non ordonnée, il n'y a pas d'ordre d'itération garanti. On ne peut donc pas utiliser cette structure pour la parallélisation. Ainsi, il faut commencer par créer un vecteur contenant les clés qui nous seront utiles pour la boucle \texttt{for}. parallélisée.

Voici la méthode modifiée, qui indique dans l'ensemble la logique de parallélisation :

\begin{minted}[breakanywhere]{c++}
bool Model::update() {
    // Copie de m_fire_front pour que tous les threads travaillent sur le même état initial
    std::unordered_map<std::size_t, std::uint8_t> current_front = m_fire_front;

    // Collection des clés pour la parallélisation
    std::vector<std::size_t> m_keys;
    for (const auto& f : current_front) {
        m_keys.push_back(f.first);
    }

    // On créé des containers pour stocker les chgangelments
    std::vector<std::unordered_map<std::size_t, std::uint8_t>> thread_local_additions;
    std::vector<std::vector<std::size_t>> thread_local_removals;

    #pragma omp parallel
    {
        #pragma omp single
        {
            int num_threads = omp_get_num_threads();
            thread_local_additions.resize(num_threads);
            thread_local_removals.resize(num_threads);
        }

        int thread_id = omp_get_thread_num();
        auto& local_additions = thread_local_additions[thread_id];
        auto& local_removals = thread_local_removals[thread_id];

        #pragma omp for schedule(dynamic, 64)
        for (size_t i = 0; i < m_keys.size(); ++i) {
        ...
        }
      ...
}
\end{minted}

Les résultats sont très mauvais. La version séquentielle est plus rapide que la version parallélisée quand celle-ci ne dispose que de peu de cœurs. Ceci est sûrement dû au fait que la version parallélisée doit créer des vecteurs pour chaque thread pour gérer la concurrence, ce qui ralentit le tout. De plus, une partie du travail ne peut toujours être effectuée que par un seul thread, c'est notamment le cas de la mise à jour de la carte globale avec les modifications calculées en parallèle.

Une explication pourrait être que le programme est \emph{memory bound}, c'est-à-dire que la vitesse d'exécution est limitée par la vitesse d'accès à la mémoire, notamment quand on crée des vecteurs, enregistre les clés, met à jour les cartes, etc.

Voici quelques résultats obtenus sur les serveurs de l'ENSTA, en désactivant l'affichage et pour une carte de 300x300.

\begin{table}[H]
  \centering
  \begin{tabular}{|c|c|c|}
    \hline
    Version               & Temps d'exécution (s) & Speedup \\ \hline
    Version initiale      & 4,1 s                 & 1,00    \\ \hline
    Parralèle - 1 coeur   & 7,55 s                & 0,54    \\ \hline
    Parralèle - 2 coeurs  & 6,76 s                & 0,61    \\ \hline
    Parralèle - 4 coeurs  & 6,98 s                & 0,59    \\ \hline
    Parralèle - 8 coeurs  & 6,35 s                & 0,65    \\ \hline
    Parralèle - 16 coeurs & 6,34 s                & 0,65    \\ \hline
    Parralèle - 80 coeurs & 6,03 s                & 0,68    \\ \hline
  \end{tabular}
  \caption{Temps d'exécution et speedup, sans affichage}
  \label{tab:execution_times}
\end{table}



\begin{figure}[H]
  \centering
  \begin{tikzpicture}
    \begin{semilogxaxis}[
        xlabel={Nombre de cœurs},
        ylabel={Speedup},
        title={Performance de la parallélisation},
        grid=both,
        xmin=0.8, xmax=100,
        ymin=0, ymax=1.1,
        xtick={1,2,4,8,16,80},
        xticklabels={1,2,4,8,16,80},
        legend pos=north east,
        width=0.8\textwidth,
        height=8cm
      ]

      % Parallel speedup
      \addplot[mark=*, color=blue] coordinates {
          (1, 0.54)
          (2, 0.61)
          (4, 0.59)
          (8, 0.65)
          (16, 0.65)
          (80, 0.68)
        };
      \addlegendentry{Version parallèle}

      % Sequential version (constant line)
      \addplot[dashed, color=red, domain=0.8:100] {1};
      \addlegendentry{Version séquentielle (référence)}

    \end{semilogxaxis}
  \end{tikzpicture}
  \caption{Comparaison des speedups en fonction du nombre de cœurs (échelle logarithmique)}
  \label{fig:execution_plot}
\end{figure}



On peut voir que le speedup obtenu lors de l'utilisation de la version parallélisée est plus petit que 1\dots, ce qui est complètement inutile.



\end{document}
